{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, SpatialDropout2D\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data variables\n",
    "x_train = None;\n",
    "x_test = None;\n",
    "y_train = None;\n",
    "y_test = None;\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = os.path.join(\"datasets\", \"mnist\");\n",
    "ROOT_LOG_DIR = 'tf_logs'\n",
    "MODEL_CHECKPOINTS = 'saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders exist. Collecting datasets...\n",
      "datasets fetched.\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist;\n",
    "\n",
    "\n",
    "def load_dataset(dataset_path=DATASET_PATH):\n",
    "    global x_train, x_test, y_train, y_test\n",
    "    if not os.path.isdir(dataset_path):\n",
    "        os.makedirs(dataset_path)\n",
    "        print('Creating folders....')\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        with open(os.path.join(dataset_path,'x_train.pickle'), 'wb') as handle:\n",
    "            pickle.dump(x_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(dataset_path,'y_train.pickle'), 'wb') as handle:\n",
    "            pickle.dump(y_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(dataset_path,'x_test.pickle'), 'wb') as handle:\n",
    "            pickle.dump(x_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(dataset_path,'y_test.pickle'), 'wb') as handle:\n",
    "            pickle.dump(y_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        print('Folders exist. Collecting datasets...')\n",
    "        with open(os.path.join(dataset_path,'x_train.pickle'), 'rb') as handle:\n",
    "            x_train= pickle.load(handle)\n",
    "        with open(os.path.join(dataset_path,'y_train.pickle'), 'rb') as handle:\n",
    "             y_train= pickle.load(handle)\n",
    "        with open(os.path.join(dataset_path,'x_test.pickle'), 'rb') as handle:\n",
    "             x_test = pickle.load(handle)\n",
    "        with open(os.path.join(dataset_path,'y_test.pickle'), 'rb') as handle:\n",
    "             y_test = pickle.load(handle)\n",
    "    print('datasets fetched.')\n",
    "load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize first six images from the Mnist data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, image in enumerate(x_train[0:6]):\n",
    "    first_image = image\n",
    "    plt.subplot(2,3,i+1, title='Label: {0}'.format(y_train[i]), xticks=[], yticks=[])\n",
    "    plt.imshow(first_image, cmap='gray')\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 8)         136       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_12 (Spatia (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 14, 14, 8)         1032      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 8)         32        \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_13 (Spatia (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               50304     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 52,826\n",
      "Trainable params: 52,794\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_filter = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "        Conv2D(num_filter,\n",
    "                 kernel_size=4,\n",
    "                 strides=(1,1),\n",
    "                 input_shape=[28,28,1],\n",
    "                 padding='same',\n",
    "                )\n",
    "         )\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(SpatialDropout2D(0.3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same', strides=(1,1)))\n",
    "model.add(\n",
    "        Conv2D(num_filter,\n",
    "                 kernel_size=4,\n",
    "                 strides=(2,2),\n",
    "                 padding='same',\n",
    "                )\n",
    "         )\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='valid', strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check input sample shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train.reshape((60000,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), 5)\n",
      "(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 0)\n",
      "(array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), 4)\n",
      "(array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 1)\n",
      "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), 9)\n",
      "(array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 2)\n",
      "(array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 1)\n",
      "(array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), 3)\n",
      "(array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 1)\n",
      "(array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y = to_categorical(\n",
    "    y_train,\n",
    "    num_classes=10\n",
    ")\n",
    "map_test = [val for val in zip(Y[0:10],y_train[0:10])]\n",
    "for val in map_test:\n",
    "    print(val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_models/20190217020145/weights.hdf5\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "53952/54000 [============================>.] - ETA: 0s - loss: 0.3441 - acc: 0.8947\n",
      "Epoch 00001: val_loss improved from inf to 0.07716, saving model to saved_models/20190217020145/weights.hdf5\n",
      "54000/54000 [==============================] - 42s 773us/step - loss: 0.3440 - acc: 0.8947 - val_loss: 0.0772 - val_acc: 0.9787\n",
      "Epoch 2/10\n",
      "23680/54000 [============>.................] - ETA: 22s - loss: 0.1558 - acc: 0.9522"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-03f2754e911a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcallback_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodelcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hands_on/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/hands_on/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hands_on/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hands_on/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "# CREATE MODEL CHECKPOINT\n",
    "modeldir = os.path.join(MODEL_CHECKPOINTS, now)\n",
    "if not os.path.isdir(modeldir):\n",
    "        os.makedirs(modeldir)\n",
    "model_file_path = modeldir+'/weights.hdf5'\n",
    "print(model_file_path)\n",
    "modelcheckpoint = ModelCheckpoint(filepath=model_file_path, verbose=1, monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "\n",
    "# INIT TENSORBOARD\n",
    "logdir = \"{}/{}\".format(ROOT_LOG_DIR, now)\n",
    "if not os.path.isdir(logdir):\n",
    "        os.makedirs(logdir)\n",
    "tensorboard = TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "# CREATE CALLBACK LIST\n",
    "callback_list = [modelcheckpoint, tensorboard]\n",
    "\n",
    "model.fit(X, Y, epochs=10, batch_size=32, validation_split=0.1, callbacks=[tensorboard, modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TEST = x_test.reshape((10000,28,28,1))\n",
    "y_pred = model.predict(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9828\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
